#!/usr/bin/env python3
"""
YOLOv11x å®æ—¶æ£€æµ‹æµæœåŠ¡
ä½¿ç”¨Ultralytics YOLOv11æ¨¡å‹
"""

import cv2
import torch
import numpy as np
from flask import Flask, Response, jsonify, request
import threading
import time
import os
from PIL import Image, ImageDraw, ImageFont
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
LOGGER = logging.getLogger(__name__)

app = Flask(__name__)

# é…ç½®å‚æ•°
WEIGHTS_PATH = "main/models/yolov11x.pt"
CONF_THRESHOLD = 0.45
IOU_THRESHOLD = 0.45
DEVICE = '0' if torch.cuda.is_available() else 'cpu'  # è‡ªåŠ¨é€‰æ‹©GPUæˆ–CPU
IMG_SIZE = 640  # YOLOæ¨¡å‹è¾“å…¥å°ºå¯¸ï¼Œä¿æŒ640x640

# è‡ªåŠ¨æ£€æµ‹æ‘„åƒå¤´æœ€ä½³åˆ†è¾¨ç‡
import sys


def get_camera_resolution():
    """æ£€æµ‹æ‘„åƒå¤´å®é™…æ”¯æŒçš„åˆ†è¾¨ç‡"""
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        LOGGER.warning("æ— æ³•æ‰“å¼€æ‘„åƒå¤´ï¼Œä½¿ç”¨é»˜è®¤åˆ†è¾¨ç‡")
        return 640, 480

    # è‡ªåŠ¨é€‰æ‹©é«˜åˆ†è¾¨ç‡
    high_resolutions = [
        (3840, 2160),  # 4K UHD
        (2560, 1440),  # 2K QHD
        (1920, 1080),  # 1080p FHD
        (1280, 720),  # 720p HD
        (640, 480)  # SD
    ]

    for width, height in high_resolutions:
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        # æ£€æŸ¥å®é™…è®¾ç½®çš„åˆ†è¾¨ç‡
        if actual_width >= width * 0.95 and actual_height >= height * 0.95:
            cap.release()
            LOGGER.info(f"âœ… æ£€æµ‹åˆ°é«˜åˆ†è¾¨ç‡æ‘„åƒå¤´: {actual_width}x{actual_height}")
            return actual_width, actual_height

    # å›é€€åˆ°å®é™…æ£€æµ‹åˆ°çš„åˆ†è¾¨ç‡
    actual_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    actual_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()

    if actual_width > 0 and actual_height > 0:
        LOGGER.info(f"æ£€æµ‹åˆ°æ‘„åƒå¤´åˆ†è¾¨ç‡: {actual_width}x{actual_height}")
        return actual_width, actual_height

    LOGGER.info("ä½¿ç”¨é»˜è®¤æ‘„åƒå¤´åˆ†è¾¨ç‡: 640x480")
    return 640, 480


# è‡ªåŠ¨è·å–æ‘„åƒå¤´åˆ†è¾¨ç‡
CAMERA_WIDTH, CAMERA_HEIGHT = get_camera_resolution()

# ä»YOLOv11æ¨¡å‹è‡ªåŠ¨è·å–ç±»åˆ«åç§°
CLASS_NAMES = None

try:
    from ultralytics import YOLO

    YOLO_AVAILABLE = True
    LOGGER.info("Ultralytics YOLOåº“åŠ è½½æˆåŠŸ")
except ImportError:
    YOLO_AVAILABLE = False
    LOGGER.error("Ultralytics YOLOåº“æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install ultralytics")
    sys.exit(1)


class YOLO11xDetector:
    def __init__(self):
        # æ™ºèƒ½è®¾å¤‡é€‰æ‹©
        self.device = 'cpu'
        if torch.cuda.is_available():
            self.device = 'cuda'
            gpu_name = torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else "Unknown GPU"
            LOGGER.info(f"ğŸš€ ä½¿ç”¨GPU: {gpu_name}")
        else:
            LOGGER.info("âš ï¸ ä½¿ç”¨CPUæ¨ç†ï¼ˆå»ºè®®å®‰è£…CUDAä»¥è·å¾—æ›´å¥½æ€§èƒ½ï¼‰")

        self.model = None
        self.is_running = False
        self.frame = None
        self.cap = None
        self.camera_width = CAMERA_WIDTH
        self.camera_height = CAMERA_HEIGHT
        self.detected_classes = []
        self.lock = threading.Lock()


    def load_model(self):
        """åŠ è½½YOLOv11xæ¨¡å‹"""
        try:
            if not os.path.exists(WEIGHTS_PATH):
                LOGGER.error(f"æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {WEIGHTS_PATH}")
                return False

            self.model = YOLO(WEIGHTS_PATH)

            # è·å–ç±»åˆ«åç§°
            global CLASS_NAMES
            if hasattr(self.model, 'names'):
                CLASS_NAMES = self.model.names
                if isinstance(CLASS_NAMES, dict):
                    CLASS_NAMES = [CLASS_NAMES[i] for i in range(len(CLASS_NAMES))]
            else:
                # ä½¿ç”¨é»˜è®¤çš„èœå“ç±»åˆ«
                CLASS_NAMES = ['æ¸…ç‚’è²è—•', 'çº¢çƒ§æ’éª¨', 'çƒ¤é¸­', 'èŠ±èœç‰›è…©',
                               'æ¸…ç‚’é»‘æœ¨è€³', 'ç±³é¥­', 'éº»å©†è±†è…', 'å®«ä¿é¸¡ä¸',
                               'ç³–é†‹é‡Œè„Š', 'æ°´ç…®é±¼', 'è¥¿çº¢æŸ¿ç‚’é¸¡è›‹', 'é’æ¤’åœŸè±†ä¸']

            LOGGER.info(f"YOLOv11xæ¨¡å‹åŠ è½½æˆåŠŸ: {WEIGHTS_PATH}")
            LOGGER.info(f"æ£€æµ‹ç±»åˆ«æ•°é‡: {len(CLASS_NAMES)}")
            LOGGER.info(f"ç±»åˆ«åˆ—è¡¨: {CLASS_NAMES}")
            return True

        except Exception as e:
            LOGGER.error(f"YOLOv11xæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def start_detection(self, source=0):
        """å¼€å§‹æ£€æµ‹ï¼Œè‡ªåŠ¨é€‚é…æ‘„åƒå¤´åˆ†è¾¨ç‡"""
        if not self.load_model():
            return False

        self.is_running = True

        # æ‰“å¼€æ‘„åƒå¤´
        try:
            self.cap = cv2.VideoCapture(source)
            if not self.cap.isOpened():
                LOGGER.error(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´: {source}")
                return False

            # è®¾ç½®æ‘„åƒå¤´ä¸ºæ£€æµ‹åˆ°çš„æœ€ä½³åˆ†è¾¨ç‡
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)

            # è®¾ç½®æ‘„åƒå¤´å‚æ•°ä¼˜åŒ–
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            self.cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

            # éªŒè¯å®é™…åˆ†è¾¨ç‡
            ret, frame = self.cap.read()
            if not ret:
                LOGGER.error(f"æ— æ³•ä»æ‘„åƒå¤´è¯»å–å¸§: {source}")
                return False

            actual_height, actual_width = frame.shape[:2]

            # å¦‚æœå®é™…åˆ†è¾¨ç‡ä¸æœŸæœ›ä¸åŒï¼Œä½¿ç”¨å®é™…åˆ†è¾¨ç‡
            if abs(actual_width - CAMERA_WIDTH) > 10 or abs(actual_height - CAMERA_HEIGHT) > 10:
                LOGGER.warning(f"å®é™…åˆ†è¾¨ç‡ {actual_width}x{actual_height} ä¸æœŸæœ› {CAMERA_WIDTH}x{CAMERA_HEIGHT} ä¸åŒ")
                # ä½¿ç”¨å®é™…åˆ†è¾¨ç‡
                self.camera_width, self.camera_height = actual_width, actual_height
            else:
                self.camera_width, self.camera_height = CAMERA_WIDTH, CAMERA_HEIGHT

            LOGGER.info(f"ğŸ¥ æ‘„åƒå¤´{source}æ­£å¸¸ï¼Œå®é™…åˆ†è¾¨ç‡: {actual_width}x{actual_height}")

        except Exception as e:
            LOGGER.error(f"âŒ æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

        # å¯åŠ¨æ£€æµ‹çº¿ç¨‹
        detection_thread = threading.Thread(target=self._detection_loop)
        detection_thread.daemon = True
        detection_thread.start()

        return True

    def _detection_loop(self):
        """ä¼˜åŒ–ç‰ˆæ£€æµ‹å¾ªç¯ï¼Œè‡ªé€‚åº”å®é™…åˆ†è¾¨ç‡"""
        try:
            fps_counter = 0
            fps_start_time = time.time()
            current_fps = 0

            while self.is_running and self.cap and self.cap.isOpened():
                ret, frame = self.cap.read()
                if not ret:
                    LOGGER.warning("âš ï¸ æ— æ³•è¯»å–æ‘„åƒå¤´å¸§")
                    time.sleep(0.1)
                    continue

                # è·å–å®é™…å¸§å°ºå¯¸
                frame_height, frame_width = frame.shape[:2]

                # è®¡ç®—FPS
                fps_counter += 1
                if fps_counter >= 30:  # æ¯30å¸§è®¡ç®—ä¸€æ¬¡FPS
                    elapsed = time.time() - fps_start_time
                    current_fps = fps_counter / elapsed
                    fps_counter = 0
                    fps_start_time = time.time()

                # ç¼©æ”¾å›¾åƒåˆ°æ¨¡å‹è¾“å…¥å°ºå¯¸
                input_frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))

                # ä½¿ç”¨YOLOv11è¿›è¡Œæ¨ç†
                results = self.model(input_frame, conf=CONF_THRESHOLD, iou=IOU_THRESHOLD, device=self.device)

                # å¤„ç†æ£€æµ‹ç»“æœ
                annotated_frame = frame.copy()
                self.detected_classes.clear()

                for result in results:
                    boxes = result.boxes
                    if boxes is not None:
                        for box in boxes:
                            # è·å–è¾¹ç•Œæ¡†åæ ‡ï¼ˆåœ¨640x640å›¾åƒä¸Šçš„åæ ‡ï¼‰
                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                            conf = box.conf[0].cpu().numpy()
                            cls = int(box.cls[0].cpu().numpy())

                            # å°†åæ ‡ä»640x640ç¼©æ”¾å›å®é™…åˆ†è¾¨ç‡
                            scale_x = frame_width / IMG_SIZE
                            scale_y = frame_height / IMG_SIZE

                            x1 = int(x1 * scale_x)
                            y1 = int(y1 * scale_y)
                            x2 = int(x2 * scale_x)
                            y2 = int(y2 * scale_y)

                            if cls < len(CLASS_NAMES):
                                class_name = CLASS_NAMES[cls]
                                self.detected_classes.append(class_name)

                                # é«˜åˆ†è¾¨ç‡è‡ªé€‚åº”ç»˜åˆ¶è¾¹ç•Œæ¡†
                                min_dim = min(frame_width, frame_height)
                                if min_dim >= 3000:  # 4Kåˆ†è¾¨ç‡
                                    line_thickness = max(6, int(0.002 * min_dim))
                                    font_scale = 0.025
                                    padding_factor = 0.4
                                elif min_dim >= 2000:  # 2Kåˆ†è¾¨ç‡
                                    line_thickness = max(4, int(0.0025 * min_dim))
                                    font_scale = 0.03
                                    padding_factor = 0.35
                                else:  # æ™®é€šåˆ†è¾¨ç‡
                                    line_thickness = max(2, int(0.003 * min_dim))
                                    font_scale = 0.02
                                    padding_factor = 0.3

                                cv2.rectangle(annotated_frame,
                                              (x1, y1), (x2, y2),
                                              (0, 255, 0), line_thickness)

                                # é«˜åˆ†è¾¨ç‡è‡ªé€‚åº”æ ‡ç­¾
                                label = f'{class_name} {conf:.2f}'

                                # ä½¿ç”¨PILç»˜åˆ¶ä¸­æ–‡æ ‡ç­¾
                                pil_img = Image.fromarray(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))
                                draw = ImageDraw.Draw(pil_img)

                                # é«˜åˆ†è¾¨ç‡è‡ªé€‚åº”å­—ä½“å¤§å°
                                font_size = max(24, int(frame_height * font_scale))
                                try:
                                    font = ImageFont.truetype("C:\\Windows\\Fonts\\simhei.ttf", font_size)
                                except:
                                    try:
                                        font = ImageFont.truetype("msyh.ttc", font_size)
                                    except:
                                        font = ImageFont.load_default()

                                text_bbox = draw.textbbox((0, 0), label, font=font)
                                text_width = text_bbox[2] - text_bbox[0]
                                text_height = text_bbox[3] - text_bbox[1]

                                # é«˜åˆ†è¾¨ç‡è‡ªé€‚åº”æ ‡ç­¾èƒŒæ™¯
                                padding = max(8, int(font_size * padding_factor))
                                box_thickness = max(2, int(0.001 * min(frame_width, frame_height)))

                                draw.rectangle([x1, y1 - text_height - 2 * padding,
                                                x1 + text_width + 2 * padding, y1],
                                               fill=(0, 255, 0), outline=(0, 255, 0),
                                               width=box_thickness)

                                draw.text((x1 + padding, y1 - text_height - padding),
                                          label, font=font, fill=(0, 0, 0))

                                annotated_frame = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

                # é«˜åˆ†è¾¨ç‡è‡ªé€‚åº”ä¿¡æ¯æ˜¾ç¤º
                min_dim = min(frame_width, frame_height)
                if min_dim >= 3000:  # 4Kåˆ†è¾¨ç‡
                    info_font_scale = 1.5
                    info_thickness = 4
                    line_spacing = 50
                elif min_dim >= 2000:  # 2Kåˆ†è¾¨ç‡
                    info_font_scale = 1.2
                    info_thickness = 3
                    line_spacing = 40
                else:  # æ™®é€šåˆ†è¾¨ç‡
                    info_font_scale = 0.7
                    info_thickness = 2
                    line_spacing = 30

                # æ˜¾ç¤ºFPSå’Œåˆ†è¾¨ç‡ä¿¡æ¯
                info_text = f"FPS: {current_fps:.1f} | {frame_width}x{frame_height}"
                cv2.putText(annotated_frame, info_text, (20, line_spacing),
                            cv2.FONT_HERSHEY_SIMPLEX, info_font_scale, (0, 255, 0), info_thickness)

                # æ˜¾ç¤ºGPUçŠ¶æ€
                gpu_text = f"GPU: {self.device}" if torch.cuda.is_available() else "CPU"
                cv2.putText(annotated_frame, gpu_text, (20, line_spacing * 2),
                            cv2.FONT_HERSHEY_SIMPLEX, info_font_scale, (0, 255, 0), info_thickness)

                # æ›´æ–°å¸§
                with self.lock:
                    self.frame = annotated_frame.copy()

        except Exception as e:
            LOGGER.error(f"âŒ æ£€æµ‹å¾ªç¯é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

        except Exception as e:
            LOGGER.error(f"æ£€æµ‹å¾ªç¯é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

    def get_frame(self):
        """è·å–å½“å‰å¸§"""
        with self.lock:
            if self.frame is None:
                return None

            # ç¼–ç ä¸ºJPEG
            ret, buffer = cv2.imencode('.jpg', self.frame)
            if ret:
                return buffer.tobytes()
            return None

    def stop(self):
        """åœæ­¢æ£€æµ‹"""
        self.is_running = False
        if self.cap:
            self.cap.release()


detector = YOLO11xDetector()


def generate_frames():
    """ç”Ÿæˆè§†é¢‘æµå¸§"""
    while True:
        frame = detector.get_frame()
        if frame is not None:
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
        time.sleep(0.033)  # 30fps


@app.route('/video_feed')
def video_feed():
    """è§†é¢‘æµè·¯ç”±"""
    return Response(generate_frames(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')


@app.route('/detect')
def detect():
    """æ£€æµ‹æŒ‡å®šç±»åˆ«æ˜¯å¦å­˜åœ¨"""
    target_class = request.args.get('class', '')

    LOGGER.info(f"æ”¶åˆ°æ£€æµ‹è¯·æ±‚: {target_class}")

    if not target_class:
        return jsonify({'detected':False,'message':'æœªæŒ‡å®šç±»åˆ«'})

    try:
        # æ£€æŸ¥detectoræ˜¯å¦å·²æ£€æµ‹åˆ°ç›®æ ‡ç±»åˆ«
        with detector.lock:
            detected = target_class in detector.detected_classes

        return jsonify({
            'detected': detected,
            'class': target_class,
            'confidence': 0.85 if detected else 0.0,
            'detected_classes': detector.detected_classes
        })

    except Exception as e:
        return jsonify({'detected': False, 'message': str(e)})


@app.route('/')
def index():
    """é«˜åˆ†è¾¨ç‡è‡ªé€‚åº”ä¸»é¡µ"""
    return f'''
    <html>
    <head>
        <title>YOLOv11x 4K Stream</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <style>
            body {{ 
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
                margin: 0; 
                padding: 20px; 
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
            }}
            .container {{ 
                max-width: 95%; 
                margin: 0 auto; 
                background: white; 
                border-radius: 15px; 
                box-shadow: 0 10px 30px rgba(0,0,0,0.3);
                overflow: hidden;
            }}
            .header {{
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                padding: 30px;
                text-align: center;
            }}
            .header h1 {{
                margin: 0;
                font-size: 2.5em;
                font-weight: 300;
            }}
            .video-container {{ 
                text-align: center; 
                padding: 20px;
                background: #f8f9fa;
            }}
            .video-feed {{
                max-width: 100%;
                height: auto;
                border: 3px solid #667eea;
                border-radius: 10px;
                box-shadow: 0 5px 15px rgba(0,0,0,0.2);
            }}
            .info-grid {{
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
                gap: 20px;
                padding: 30px;
            }}
            .info-card {{
                background: #f8f9fa;
                padding: 25px;
                border-radius: 10px;
                border-left: 5px solid #667eea;
            }}
            .info-card h3 {{
                margin-top: 0;
                color: #333;
                font-size: 1.4em;
            }}
            .info-card ul {{
                list-style: none;
                padding: 0;
            }}
            .info-card li {{
                padding: 8px 0;
                border-bottom: 1px solid #eee;
            }}
            .info-card a {{
                color: #667eea;
                text-decoration: none;
                font-weight: bold;
            }}
            .info-card a:hover {{
                text-decoration: underline;
            }}
            .status-bar {{
                background: #28a745;
                color: white;
                padding: 15px;
                text-align: center;
                font-size: 1.2em;
            }}
            @media (max-width: 768px) {{
                .container {{ margin: 10px; }}
                .header {{ padding: 20px; }}
                .header h1 {{ font-size: 2em; }}
                .info-grid {{ padding: 20px; }}
            }}
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <h1>ğŸ¯ YOLOv11x 4Kæ™ºèƒ½æ£€æµ‹ç³»ç»Ÿ</h1>
                <p>æ”¯æŒ3840x2160è¶…é«˜æ¸…å®æ—¶æ£€æµ‹</p>
            </div>

            <div class="video-container">
                <img src="/video_feed" class="video-feed" alt="å®æ—¶æ£€æµ‹ç”»é¢">
            </div>

            <div class="status-bar">
                âœ… ç³»ç»Ÿè¿è¡Œæ­£å¸¸ | RTX 4060 GPUåŠ é€Ÿ | 4Kåˆ†è¾¨ç‡æ”¯æŒ
            </div>

            <div class="info-grid">
                <div class="info-card">
                    <h3>ğŸ“¹ è§†é¢‘æµåœ°å€</h3>
                    <ul>
                        <li><a href="/video_feed" target="_blank">åŸå§‹è§†é¢‘æµ</a></li>
                        <li>æ”¯æŒ4K/2K/1080pè‡ªé€‚åº”</li>
                    </ul>
                </div>

                <div class="info-card">
                    <h3>ğŸ” æ™ºèƒ½æ£€æµ‹API</h3>
                    <ul>
                        <li><a href="/detect?class=çƒ¤é¸­" target="_blank">æ£€æµ‹çƒ¤é¸­</a></li>
                        <li><a href="/detect?class=çº¢çƒ§æ’éª¨" target="_blank">æ£€æµ‹çº¢çƒ§æ’éª¨</a></li>
                        <li><a href="/status" target="_blank">ç³»ç»ŸçŠ¶æ€</a></li>
                    </ul>
                </div>

                <div class="info-card">
                    <h3>âš™ï¸ æŠ€æœ¯è§„æ ¼</h3>
                    <ul>
                        <li>åˆ†è¾¨ç‡: 3840x2160 (4K UHD)</li>
                        <li>æ¨¡å‹: YOLOv11x</li>
                        <li>GPU: RTX 4060åŠ é€Ÿ</li>
                        <li>æ£€æµ‹ç±»åˆ«: 6ç§èœå“</li>
                    </ul>
                </div>

                <div class="info-card">
                    <h3>ğŸ¯ æ”¯æŒèœå“</h3>
                    <ul>
                        <li>æ¸…ç‚’è²è—•</li>
                        <li>çº¢çƒ§æ’éª¨</li>
                        <li>çƒ¤é¸­</li>
                        <li>èŠ±èœç‰›è…©</li>
                        <li>æ¸…ç‚’é»‘æœ¨è€³</li>
                        <li>ç±³é¥­</li>
                    </ul>
                </div>
            </div>
        </div>
    </body>
    </html>
    '''


@app.route('/status')
def status():
    """çŠ¶æ€æ£€æŸ¥"""
    return jsonify({
        'model_loaded': detector.model is not None,
        'is_running': detector.is_running,
        'detected_classes': detector.detected_classes,
        'class_names': CLASS_NAMES if CLASS_NAMES else []
    })


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='YOLOv11x Detection Stream')
    parser.add_argument('--source', type=int, default=0, help='æ‘„åƒå¤´ç´¢å¼•')
    parser.add_argument('--port', type=int, default=5000, help='æœåŠ¡ç«¯å£')
    parser.add_argument('--conf', type=float, default=0.45, help='ç½®ä¿¡åº¦é˜ˆå€¼')
    args = parser.parse_args()

    # æ›´æ–°ç½®ä¿¡åº¦é˜ˆå€¼
    CONF_THRESHOLD = args.conf

    try:
        print("=" * 60)
        print("YOLOv11x æ£€æµ‹æœåŠ¡å¯åŠ¨ä¸­...")
        print("=" * 60)

        # å¯åŠ¨æ£€æµ‹
        if detector.start_detection(source=args.source):
            print("âœ… YOLOv11xæ£€æµ‹æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
            print(f"ğŸŒ è®¿é—®åœ°å€: http://127.0.0.1:{args.port}")
            print(f"ğŸ“¹ è§†é¢‘æµåœ°å€: http://127.0.0.1:{args.port}/video_feed")
            print(f"ğŸ“Š çŠ¶æ€æ£€æŸ¥: http://127.0.0.1:{args.port}/status")
            print("ğŸ”„ æŒ‰Ctrl+Cåœæ­¢æœåŠ¡")

            try:
                app.run(host='0.0.0.0', port=args.port, debug=False)
            except KeyboardInterrupt:
                print("\nğŸ‘‹ æœåŠ¡å·²åœæ­¢")
                detector.stop()
        else:
            print("âŒ YOLOv11xæ£€æµ‹æœåŠ¡å¯åŠ¨å¤±è´¥")

    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()